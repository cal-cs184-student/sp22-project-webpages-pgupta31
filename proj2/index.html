<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2022</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Parth Gupta, Code: <a href="https://github.com/cal-cs184-student/p1-rasterizer-sp22-pgupta31">cal-cs184-student/pgupta31</a>, <a href="https://cal-cs184-student.github.io/sp22-project-webpages-pgupta31/proj1/index.html">Writeup</a></h2>

<br>

<div>

<h2 align="middle">Overview</h2>

<p> 

This project was super cool! I started off by implementing simple triangle rasterization, with only sampling once per pixel value in order to produce single-color triangles. This posed some aliasing issues (jaggies, discontinuities, etc.), so supersampling was used as a preliminary method to reduce the aliasing effects. I also got to implement hierarchical transforms, enabling us to transform (stretch, translate, etc.) shapes on the screen. In the second half of the project, I implemented methods to map textures onto shapes. This texture mapping process was then enhanced using various pixel and level sampling techniques, ultimately allowing our images to look visually smoother and more accurate. <br> <br>

As a whole, I think I learned a whole lot of things from this project! First, I think the techniques we used to antialias our single-color triangles was really cool. It's interesting how averaging multiple locations within a pixel can make shapes like triangles look so much smoother. Moreover, I really enjoyed applying my transforms to cubeman. It really reiterated the fact that the order we apply transformations can definitely make a difference, and gave me a chance to play around with the transformations I implemented. Finally, I never really knew how textures were mapped onto images. It was interesting to not only get these to map onto the images, but also explore various ways to make the textures themselves smoother, particularly through bilinear sampling. <br> <br>

Overall, the project was a great learning experience, and I'm looking forward to future projects in this class!

</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

<ol>
  <li> <p> <b> <u> Explanation of Rasterizing Triangles:</u> </b> 

    In order to rasterize triangles, we first determine the implicit line equation for each of the three lines that make up the edges of the triangle. The format of these equations was derived in lecture (based on the directional vector from one point to another and the normal vector for the line). More specifically, given a point (x,y) and the line connecting (x0,y0) and (x0,y0), we can determine which side of the line that (x,y) falls on based on the sign of L(x,y) = -(x-x0)(y1-y0) + (y-y0)(x1-x0).

    We then determine a bounding box, based on the smallest/largest x and y values for the three vertices of the triangle. Since these are continuous values (donâ€™t necessarily lie on the boundary of a pixel), we do some processing to convert these to ints to determine the bounding region.

    We then proceed by sampling once per pixel within this bounding box (in this case, we sampled in the center for each pixel). For each of these points (of the form (x,y)), we run them through the 3 implicit line equations, which give us an indication of which side of the lines that the point falls on. If the point falls on the same side of all three lines (means that L(x,y) <= 0 for all three or L(x,y) >= 0 for all three), then we know that the pixel location is within the triangle, so we can fill its color accordingly. Note that by checking both directions (all negative or all positive), we take care of accounting for the fact that the points could be provided both clockwise or counterclockwise. 

    The only other check needed is to ensure that we are within the bounds of the image/output, so we additionally check to make sure that we are within the image boundaries.

  </p> </li>

  <li> <p> My algorithm is no worse than checking each sample within the bounding box of the triangle because that is exactly what I did! I determined the bounding box based on the smallest/largest x and y values for the three vertices of the triangle and iterated through the pixels of this bounding region. As a side note, I did enhance this naive implementation with some optimizations (described in the extra credit portion below!), in order to speed up the performance a bit. </p> </li>

  <li> <p> Below is an example of a rasterized image using the method described above (png screenshot of basic/test4.svg). We see that there are jaggies present and some discontinuities, particularly towards the vertices of the triangles. This is the issue that we addressed in the next task. </p> </li>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task1_writeup.png" align="middle" width="400px"/>
          <figcaption align="middle">basic/test4.svg</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <li> <b> <u> Extra Credit:</u> </b> 

    In order to speed up my sampling implementation, I first eliminated the extra checks to see if x and y were out of bounds by clamping the bounding box when initially calculating it (so that I don't need to check on every iteration of the loop). After this, I tried to eliminate the need to check excess pixels by stopping each iteration after we fall outside the triangle for that column. This follows from the fact that once we have passed through the triangle and are now outside the triangle, we know that we can skip the rest of the pixels for that column, and can continue onto the next column. Both of these seemed to help the speed (resulted in an 8.5% speedup). The last thing I tried was switching the order of the for loops (so I tried iterating row by row instead of column by column). Interestingly, this resulted in a smaller speedup (only around 7.5%), so I stuck with the initial two optimizations as described above.

    The tables below show the resulting speeds for varous svg files in the basic directory (along with a custom svg I made) for both the naive and optimized implementation: </li>

    <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task1_extra_naive.png" align="middle" width="700px"/>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/task1_extra_optimized.png" align="middle" width="800px"/>
        </td>
      </tr>
    </table>
  </div>

</ol>

<h3 align="middle">Part 2: Antialiasing triangles</h3>

<ol>
  <li> <p> <b> <u> Explanation of Supersampling:</u> </b> 

    My supersampling algorithm works pretty similarly to the algorithm from task 1. I determined the line equations for the three edges and the bounding box coordinates in the same way as task 1 (see explanation in previous section). The main difference is that we now sample <code>sample_rate</code> times per pixel. This involved another set of nested for loops so that we could sample at different subsections in the pixel. Additionally, instead of directly calling fill_pixel, we now write the color value to the appropriate index of the sample_buffer vector if that subsection of the pixel is within the triangle. This allows us to then compute an average of the entries for a specific pixel before writing it to the frame buffer (described below).

  </p> </li>

  <li> <p> <b> <u> Why it is useful:</u> </b> 

    Supersampling is useful primarily to reduce aliasing effects. By sampling at multiple locations within a pixel and averaging their values (if they lie within a given triangle), we see that our lines are smoother and we have fewer jaggies.

  </p> </li>

  <li> <p> <b> <u> Modifications to the Pipeline:</u> </b> 

    I first modified the triangle rasterization algorithm (as described in the supersampling description above), which took care of sampling at multiple locations within each pixel. In resolve_to_framebuffer(), this then allows us to compute an average of the entries for a specific pixel, and set the pixel color to match the average. One other key change was ensuring that the sample_buffer gets resized to size <code>width * height * sample_rate</code> so that we have enough space for the entries. Additionally, <code>fill_pixel()</code> was also modified to write to <b>all</b> the indices of sample_buffer corresponding to that pixel coordinate. This accounted for correctly rasterizing lines and points (which call the <code>fill_pixel()</code> method).

  </p> </li>

  <li> <p> <b> <u> How Supersampling Does Antialising:</u> </b> 

    Our method of supersampling does antialiasing by averaging various samples within each pixel. As we learned in class, this procedure essentially filters out higher frequencies (which are present at the edges / sharp color changes), thereby creating smoother transitions.

  </p> </li>

  <li> <p> Below are screenshots of test4.svg with different supersampling rates. The results shown in the screenshots below are observed because our supersampling algorithm is working to reduce aliasing. As seen with a sampling rate of 1 per pixel, we have visible jaggies and some visual discontinuities in the coloring. However, as we increase the sampling rate to 16, there are smoother edges to the shapes and less discontinuities, since each pixelâ€™s color reflects an average of multiple samples.

  </p> </li>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task2_writeup_1.png" align="middle" width="400px"/>
          <figcaption align="middle">Rate of 1 per pixel</figcaption>
        </td>
        <td>
          <img src="images/task2_writeup_4.png" align="middle" width="400px"/>
          <figcaption align="middle">Rate of 4 per pixel</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/task2_writeup_16.png" align="middle" width="400px"/>
          <figcaption align="middle">Rate of 16 per pixel</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <li> <p> <b> <u> Extra Credit:</u> </b> 

    I implemented jittered supersampling! To do this, I added a condition to <code>DrawRend::keyboard_event</code> that updates my newly added jittered value when 'J' is pressed (toggling jittered sampling on/off). Instead of sampling at the center of each supersample region (as implemented in normal supersampling above), I now included a conditional in <code>rasterize_triangle</code> that checks if jittered is set to be on (i.e. <code>jittered</code> is an odd number). If this is the case, I still go through the normal supersmapling procedure (depending on the sampling rate), but the location within each supersample region is determined by a random number (using the <code>rand()</code> function). As a result, we see that this produces some variability in the output renderings. For low sampling rates, we see that this randomness actually can make the edges of the triangles look a bit bumpier (not too ideal), but for higher sampling rates, we see that the randomness actually helps make the triangles look a bit more continuous and helps eliminate some of the aliasing present towards the triangle vertices. This is seen in the comparison screenshots below: </p> </li>

    <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task2_extra_1_none.png" align="middle" width="400px"/>
          <figcaption align="middle">1 per pixel (no jittering)</figcaption>
        </td>
        <td>
          <img src="images/task2_extra_1_jitter.png" align="middle" width="400px"/>
          <figcaption align="middle">1 per pixel (jittering)</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/task2_extra_16_none.png" align="middle" width="400px"/>
          <figcaption align="middle">16 per pixel (no jittering)</figcaption>
        </td>
        <td>
          <img src="images/task2_extra_16_jitter.png" align="middle" width="400px"/>
          <figcaption align="middle">16 per pixel (jittering)</figcaption>
        </td>
      </tr>
    </table>
  </div>

</ol>

<h3 align="middle">Part 3: Transforms</h3>

Cubeman is now doing jumping jacks! In order to do this, I added rotations to the upper half of both legs and translated both halves of both legs to make it seem like cube manâ€™s legs were bent outwards. Moreover, I rotated both section of the arms, and added a translation to the outer portions so that it would appear that cubemanâ€™s arms were directed upwards. See the screenshot below. <br>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task3_writeup.png" align="middle" width="400px"/>
      </td>
    </tr>
  </table>
</div>

<p> <b> <u> Extra Credit:</u> </b> 

    I added the ability for the user to rotate the viewport both counterclockwise and clockwise. Pressing 'Q' rotates the viewport counterclockwise 90 degrees, while pressing 'W' rotates the viewport clockwise 90 degrees. 

    In order to implement this change, I added a state variable to represent the rotation amount in degrees, which now gets updated in the <code>DrawRend::keyboard_event</code> function when 'Q' or 'W' is pressed (decremented/incremented by 90 degrees). I also maintained a rotation matrix, which was also updated on pressing these keys, using the rotate() function I implemented earlier in this task. 

    In terms of the SVG to NDC and NDC to screen-space matrix stack, the key idea was to translate all the points/values by an offset equivalent to half the width and half the height of the svg. This is because we want to perform rotations on the center of the image, rather than the corner (this was a bug that took me a long time to understand!). As a result, I constructed a transformation matrix that (from right to left) translates the input an offset equivalent to the center of the image, rotates it around (0,0), and translates it back. I added this transformation matrix to the transformations present in the <code>DrawRend::redraw()</code> function, specifically applied before transforming from SVG to NDC and NDC to screen-space, since the order of matrix multiplication matters.

    The results of this are shown in the lion screenshots below:

  </p>

  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task3_extra_left.png" align="middle" width="400px"/>
        <figcaption align="middle">Rotated Clockwise 90 Degrees</figcaption>
      </td>
      <td>
        <img src="images/task3_extra_right.png" align="middle" width="400px"/>
        <figcaption align="middle">Rotated Counterclockwise 90 Degrees</figcaption>
      </td>
    </tr>
  </table>
</div>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

At a high level, Barycentric coordinates allow us to interpolate texture values at the three vertices of a given triangle. This allows us to obtain a smooth varying value across the surface of the triangle (see triangle screenshot on the left below). In this specific example, we did this with colors, but we could also do it with textures. In order to work with Barycentric coordinates, we essentially work with a new coordinate system for triangles (alpha, beta, and gamma), and can solve for the proportion of color from each of the three vertices that are present at a specific location (x,y) using these Barycentric coordinates. This follows from the form (x,y) = alpha * A + beta * B + gamma * C, where A, B, and C are the three vertices of the triangle. We also enforce that alpha, beta, and gamma all add up to 1 so that this equation acts as a weighted sum of the three vertices, thereby giving continuity to the textures across the triangle region. We can see this in the triangle rendering shown below. This technique was applied to the circle on the righthand side, as we interpolated colors across each of the triangles in the svg file, producing a smooth color blend across the circle.

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task4_writeup_tri.png" align="middle" width="400px"/>
          <figcaption align="middle">Triangle Coloring with Barycentric Coordinates</figcaption>
        </td>
        <td>
          <img src="images/task4_writeup.png" align="middle" width="400px"/>
          <figcaption align="middle">test7.svg</figcaption>
        </td>
      </tr>
    </table>
  </div>

<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

<ol>
  <li> <p> <b> <u> Explanation of Pixel Sampling:</u> </b> 

    Since textures/colors are continuous, pixel sampling essentially allows us to sample the corresponding texture/color for a coordinate location. In order to perform texture mapping, we used pixel sampling in order to sample pixels from texture space (using Barycentric coordinates) for each (x,y) location in our bounding box, and apply that color/texture accordingly to that (x,y) location.

    First, nearest neighbor pixel sampling works by returning the color of the nearest texture coordinate (in the space defined by the current mipmap layer) from the scaled (u,v) coordinate that we would like to texturize. The scaled (u,v) coordinate is scaled by the width and height of the mipmap layer (in pixels), and we then round this value to find the nearest texture coordinate.

    Bilenar pixel sampling works similarly, but returns a weighted average of the colors at the four nearest neighbors. This is done with the help of a lerp function (as defined in the code). Because weâ€™re doing a weighted average, bilinear pixel sampling is pretty similar conceptually to the supersampling we implemented in task 2, the main difference being the additional weights.

  </p> </li>

  <li> As shown in the images below, bilinear sampling creates a smoother effect than nearest neighbor sampling. We expect this to occur especially when there are higher frequencies (here we are changing textures/colors very quickly) so we see that bilinear sampling performs better. Moreover, we see that sampling at a rate of 16 per pixel also creates a more continuous effect for the colors, preventing aliasing. This follows from the principles of supersampling above, since we are averaging multiple locations in order to filter out the high frequencies. Overall, we see that the 16 per pixel sampling rate combined with bilinear sampling performs best visually, as expected. </li>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task5_nearest1.png" align="middle" width="400px"/>
          <figcaption align="middle">nearest sampling at 1 sample per pixel</figcaption>
        </td>
        <td>
          <img src="images/task5_nearest16.png" align="middle" width="400px"/>
          <figcaption align="middle">nearest sampling at 16 samples per pixel</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/task5_bilinear1.png" align="middle" width="400px"/>
          <figcaption align="middle">bilinear sampling at 1 sample per pixel</figcaption>
        </td>
        <td>
          <img src="images/task5_bilinear16.png" align="middle" width="400px"/>
          <figcaption align="middle">bilinear sampling at 16 samples per pixel</figcaption>
        </td>
      </tr>
    </table>
  </div>

</ol>

<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

<ol>
  <li> <p> <b> <u> Explanation of Level Sampling:</u> </b> 

    Level sampling is the process by which we sample from mipmaps, allowing us to choose a specific mipmap layer to use based on which texture layer best approximates the screen sampling rate (layer 0 is has highest resolution, while higher layers have lower resolution). From task 5, we have already determined the (u,v) texture coordinates for each (x,y) coordinate that we are sampling from, which is stored in the p_uv field of the SampleParams struct. The only other step is to determine the (u,v) coordinates for (x+1,y) and (x,y+1), using the same barycentric interpolation method from earlier. This allows us to determine approximate values for du/dx, dv/dx, du/dy, and dv/dy (scaled appropriately by the width and height of the texture image).

    For doing level sampling based on the nearest mipmap layer, we simply computed D based on the formula described in lecture, giving us the best layer for texture sampling. For linear level sampling, we did this with the lerp function described earlier, interpolated between the two closest mipmap layers and weighted based on the distances from each of them (a value that ranges between 0 and 1).

    Itâ€™s interesting because this simply allows us to choose which levels to sample from, but then our code from task 5 then decides how to sample the actual texture pixels on the layers we choose using pixel sampling methods.

  </p> </li>

  <li> <p> <b> <u> Discussion of Tradeoffs:</u> </b> 

    Since we can now adjust our sampling technique by selecting pixel sampling, level sampling, or the number of samples per pixel, we can discuss some of the tradeoffs between them. <br> <br>

    For choosing the number of samples per pixel, we see that supersampling leads to more memory usage. This is because we have to dynamically increase the size of our sample buffer accordingly based on the sampling rate (to be of size <code>width*height*sample_rate</code>). Moreover, we need to perform more iterations (iterating <code>sample_rate</code> times per pixel) in order to determine the color samples to place in the sample buffer. Therefore, we see that supersampling per pixel can lead to a decrease in speed and requires more memory. However, as weâ€™ve seen, supersampling is a great way to prevent aliasing, since we are effectively filtering out the higher frequencies by averaging multiple locations within each pixel, thereby creating a more continuous effect on the image and preventing artifacts like jaggies. <br> <br>

    For pixel sampling, we implemented two main methods: nearest neighbor and bilinear sampling. We see that bilinear sampling requires much more computation than nearest neighbor sampling, since we must perform linear interpolation among 4 texel samples (rather than returning a single texel sample). There isnâ€™t too much of a difference in terms of memory usage between the two, since we arenâ€™t really storing many intermediate values. Lastly, as seen visually in the rendered images, we see that bilinear sampling is much better for antialising than nearest neighbor pixel sampling. As explained earlier, by performing a weighted average of the four nearest texture samples for each of the points that we are sampling at, we create less discontinuity in the textures that we map onto our image. <br> <br>

    For level sampling, we implemented three main methods: level 0, nearest level, and linearly interpolating between the two nearest levels. We see that simply returning the 0th mipmap layer (full resolution) is the quickest and requires the least memory. However, we get antialiasing benefits for doing one of the other two level sampling methods. Linearly interpolating requires more time than nearest level sampling because we must compute the lerp function and sample at two different layers rather than just one. There isnâ€™t much of a memory difference between nearest level and linear interpolating between two layers because the mipmap layers are already precomputed, so itâ€™s mainly a computational difference. As stated with the other two techniques, linear level sampling will be the best for antialiasing because it produces a smoother result between the texture layers selected for neighboring triangles.

  </p> </li>

  <li> <p> See below for four different versions of the same image, using the pixel and level sampling methods implemented in the last few tasks. 

  </p> </li>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/task6_1.png" align="middle" width="400px"/>
          <figcaption align="middle">L_ZERO + P_NEAREST</figcaption>
        </td>
        <td>
          <img src="images/task6_1.png" align="middle" width="400px"/>
          <figcaption align="middle">L_ZERO + P_LINEAR</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/task6_3.png" align="middle" width="400px"/>
          <figcaption align="middle">L_NEAREST + P_NEAREST</figcaption>
        </td>
        <td>
          <img src="images/task6_4.png" align="middle" width="400px"/>
          <figcaption align="middle">L_NEAREST + P_LINEAR</figcaption>
        </td>
      </tr>
    </table>
  </div>

</ol>

<h2 align="middle">Section III: Art Competition</h2>

<h3 align="middle">Part 7: Draw something interesting!</h3>

